{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff134f10-c9bb-44a5-a73c-1459d4883b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e64748-7319-41e6-8730-9ca04527f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch stock data from Yahoo Finance\n",
    "def fetch_yahoo_finance_data(ticker, start_date, end_date):\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    return data\n",
    "\n",
    "# Function to fetch data from Alpha Vantage\n",
    "def fetch_alpha_vantage_data(ticker, api_key):\n",
    "    ts = TimeSeries(key=api_key, output_format='pandas')\n",
    "    data, meta_data = ts.get_daily(symbol=ticker, outputsize='full')\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d56dbe8-bd9b-429d-929d-36d247dd4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the data\n",
    "def clean_data(data):\n",
    "    data = data.drop_duplicates()\n",
    "    data = data.fillna(method='ffill').fillna(method='bfill')\n",
    "    return data\n",
    "\n",
    "# Function to normalize the data\n",
    "def normalize_data(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns, index=data.index)\n",
    "    return normalized_data\n",
    "\n",
    "# Function to standardize the data\n",
    "def standardize_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    standardized_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns, index=data.index)\n",
    "    return standardized_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecc9e479-1237-45cb-accd-d65cf823a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save DataFrame to MongoDB\n",
    "def save_to_mongo(collection_name, data, db):\n",
    "    collection = db[collection_name]\n",
    "    collection.delete_many({})  # Clear existing data\n",
    "    collection.insert_many(data.reset_index().to_dict('records'))\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['financial_data']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19bff898-ef8b-4b15-a43e-8a75042a52e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "C:\\Users\\PAVAN\\AppData\\Local\\Temp\\ipykernel_8056\\2877712375.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data = data.fillna(method='ffill').fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - MSE: 0.00048421203025467683, R2: 0.9995544638971565\n",
      "Gradient Boosting - MSE: 0.00043620965950665514, R2: 0.9995986321289517\n"
     ]
    }
   ],
   "source": [
    "# Fetch, clean, normalize, and standardize data\n",
    "yahoo_data = fetch_yahoo_finance_data('AAPL', '2020-01-01', '2023-01-01')\n",
    "alpha_data = fetch_alpha_vantage_data('AAPL', 'USLF3P1QRCK9TLCC')\n",
    "cleaned_yahoo_data = clean_data(yahoo_data)\n",
    "cleaned_alpha_data = clean_data(alpha_data)\n",
    "normalized_yahoo_data = normalize_data(cleaned_yahoo_data)\n",
    "standardized_yahoo_data = standardize_data(cleaned_yahoo_data)\n",
    "\n",
    "# Save the data to MongoDB\n",
    "save_to_mongo('yahoo_finance', cleaned_yahoo_data, db)\n",
    "save_to_mongo('alpha_vantage', cleaned_alpha_data, db)\n",
    "save_to_mongo('normalized_yahoo_finance', normalized_yahoo_data, db)\n",
    "save_to_mongo('standardized_yahoo_finance', standardized_yahoo_data, db)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X = standardized_yahoo_data.drop('Close', axis=1)\n",
    "y = standardized_yahoo_data['Close']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the models\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "gb_predictions = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the models\n",
    "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "gb_mse = mean_squared_error(y_test, gb_predictions)\n",
    "gb_r2 = r2_score(y_test, gb_predictions)\n",
    "\n",
    "print(f\"Random Forest - MSE: {rf_mse}, R2: {rf_r2}\")\n",
    "print(f\"Gradient Boosting - MSE: {gb_mse}, R2: {gb_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d962b6e5-ab10-403e-a2b7-458df028e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to forecast future values using trained models\n",
    "def forecast_future_values(model, data, periods=30):\n",
    "    # Ensure that the data has no missing values\n",
    "    data = data.ffill().bfill()\n",
    "    \n",
    "    # Generate future dates\n",
    "    last_date = data.index[-1]\n",
    "    future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=periods, freq='D')\n",
    "    future_data = pd.DataFrame(index=future_dates)\n",
    "    \n",
    "    # Ensure the future_data DataFrame has the same columns as data\n",
    "    future_features = pd.DataFrame(index=future_dates, columns=data.columns)\n",
    "    \n",
    "    # Fill the future_features DataFrame with the last known values\n",
    "    for col in data.columns:\n",
    "        future_features[col] = data[col].iloc[-1]\n",
    "    \n",
    "    # Reindex future_features to ensure it has all columns\n",
    "    future_features = future_features.fillna(0)\n",
    "    \n",
    "    # Align feature names to match those used during training\n",
    "    if hasattr(model, 'feature_names_in_'):\n",
    "        missing_cols = set(model.feature_names_in_) - set(future_features.columns)\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Feature names missing in future data: {missing_cols}\")\n",
    "    \n",
    "    # Ensure future_features has the correct columns order\n",
    "    future_features = future_features[model.feature_names_in_]\n",
    "    \n",
    "    # Make predictions\n",
    "    future_predictions = model.predict(future_features)\n",
    "    \n",
    "    return future_data, future_predictions\n",
    "\n",
    "# Forecast future values\n",
    "rf_future_data, rf_future_predictions = forecast_future_values(rf_model, cleaned_yahoo_data)\n",
    "gb_future_data, gb_future_predictions = forecast_future_values(gb_model, cleaned_yahoo_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e91328ae-1cef-4f97-b70e-e17e726e0491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to cleaned_data.csv\n",
      "Data saved to normalized_data.csv\n",
      "Data saved to standardized_data.csv\n",
      "Data saved to future_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Function to save DataFrame to CSV\n",
    "def save_to_csv(df, filename):\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "# Save results to CSV\n",
    "save_to_csv(cleaned_yahoo_data, 'cleaned_data.csv')\n",
    "save_to_csv(normalized_yahoo_data, 'normalized_data.csv')\n",
    "save_to_csv(standardized_yahoo_data, 'standardized_data.csv')\n",
    "save_to_csv(pd.DataFrame({'Date': rf_future_data.index, 'Predicted': rf_future_predictions}), 'future_predictions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7f95571-92d4-41d8-b20f-b63548717353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal portfolio weights: [0.00000000e+00 4.54775626e-18 8.91904395e-01 0.00000000e+00\n",
      " 0.00000000e+00 1.08095605e-01]\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate portfolio return and risk\n",
    "def portfolio_performance(weights, returns):\n",
    "    portfolio_return = np.sum(returns.mean() * weights) * 252\n",
    "    portfolio_risk = np.sqrt(np.dot(weights.T, np.dot(returns.cov() * 252, weights)))\n",
    "    return portfolio_return, portfolio_risk\n",
    "\n",
    "# Function to minimize the negative Sharpe ratio\n",
    "def minimize_sharpe_ratio(weights, returns, risk_free_rate=0.01):\n",
    "    portfolio_return, portfolio_risk = portfolio_performance(weights, returns)\n",
    "    return - (portfolio_return - risk_free_rate) / portfolio_risk\n",
    "\n",
    "# Optimization constraints\n",
    "def optimize_portfolio(returns):\n",
    "    num_assets = len(returns.columns)\n",
    "    initial_weights = num_assets * [1. / num_assets]\n",
    "    bounds = tuple((0, 1) for asset in range(num_assets))\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    \n",
    "    result = minimize(minimize_sharpe_ratio, initial_weights, args=(returns,), method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result.x\n",
    "\n",
    "# Example usage\n",
    "historical_returns = cleaned_yahoo_data.pct_change().dropna()\n",
    "optimal_weights = optimize_portfolio(historical_returns)\n",
    "\n",
    "print(f\"Optimal portfolio weights: {optimal_weights}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ec3f490-a932-4356-b9d7-dcc054a66477",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PAVAN\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\PAVAN\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\PAVAN\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected anomalies: Date\n",
      "2020-01-02   -43.661170\n",
      "2020-07-31     9.986509\n",
      "2020-09-03   -10.473174\n",
      "2022-01-28    11.259786\n",
      "2022-10-28    11.036419\n",
      "2022-11-10    12.059666\n",
      "dtype: float64\n",
      "Monte Carlo simulation results: [3.5224411779332154, 0.9135045360115304, 0.7777819569384445, 0.9624955917571822, 0.4488943567418513, 1.1264682766308853, -0.10669153345227222, 2.3318799308775744, 0.8750042054194229, -0.20236755405753626]\n"
     ]
    }
   ],
   "source": [
    "# Anomaly detection function\n",
    "def detect_anomalies(data):\n",
    "    residuals = sm.tsa.ARIMA(data, order=(1, 0, 0)).fit().resid\n",
    "    std_residuals = np.std(residuals)\n",
    "    anomalies = residuals[np.abs(residuals) > 3 * std_residuals]\n",
    "    return anomalies\n",
    "\n",
    "# Monte Carlo simulation function\n",
    "def monte_carlo_simulation(returns, num_simulations=1000):\n",
    "    simulation_results = []\n",
    "    for _ in range(num_simulations):\n",
    "        simulated_returns = np.random.choice(returns, size=len(returns))\n",
    "        simulated_cumulative_returns = np.cumprod(1 + simulated_returns) - 1\n",
    "        simulation_results.append(simulated_cumulative_returns[-1])\n",
    "    return simulation_results\n",
    "\n",
    "# Example usage\n",
    "anomalies = detect_anomalies(cleaned_yahoo_data['Close'])\n",
    "simulation_results = monte_carlo_simulation(historical_returns['Close'])\n",
    "\n",
    "print(f\"Detected anomalies: {anomalies}\")\n",
    "print(f\"Monte Carlo simulation results: {simulation_results[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d80101bd-97ba-42f4-841a-32295d0b9a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc9740b2a2c4c75abb2064b65a98c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Ticker:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d457bd444254fafad4c760fed541e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Start Date:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47abea1ff7de48c0bf54ead6e2cd0c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='End Date:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c963a6cb16454583995f1dfd4f280209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Stock Prices\n",
    "def plot_stock_prices(data):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(data.index, data['Close'], label='Close Price')\n",
    "    plt.title('Stock Prices Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot Future Predictions\n",
    "def plot_future_predictions(future_df):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(future_df['Date'], future_df['Predicted'], label='Predicted Future Prices', color='orange')\n",
    "    plt.title('Future Price Predictions')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Predicted Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# User Interface with Download Options\n",
    "def create_user_interface_with_downloads():\n",
    "    ticker_input = widgets.Text(description='Ticker:')\n",
    "    start_date_input = widgets.Text(description='Start Date:')\n",
    "    end_date_input = widgets.Text(description='End Date:')\n",
    "    submit_button = widgets.Button(description='Submit')\n",
    "    \n",
    "    def on_button_click(b):\n",
    "        ticker = ticker_input.value\n",
    "        start_date = start_date_input.value\n",
    "        end_date = end_date_input.value\n",
    "        data = fetch_yahoo_finance_data(ticker, start_date, end_date)\n",
    "        cleaned_data = clean_data(data)\n",
    "        normalized_data = normalize_data(cleaned_data)\n",
    "        standardized_data = standardize_data(cleaned_data)\n",
    "        \n",
    "        # Save results to CSV\n",
    "        save_to_csv(cleaned_data, 'cleaned_data.csv')\n",
    "        save_to_csv(normalized_data, 'normalized_data.csv')\n",
    "        save_to_csv(standardized_data, 'standardized_data.csv')\n",
    "        \n",
    "        # Forecast future values\n",
    "        rf_future_data, rf_future_predictions = forecast_future_values(rf_model, cleaned_data)\n",
    "        future_df = pd.DataFrame({'Date': rf_future_data.index, 'Predicted': rf_future_predictions})\n",
    "        save_to_csv(future_df, 'future_predictions.csv')\n",
    "        \n",
    "        # Display cleaned data\n",
    "        display(HTML(\"<h3>Cleaned Data</h3>\"))\n",
    "        display(cleaned_data.head().style.set_table_attributes('class=\"table table-striped\"').set_caption(\"Cleaned Data\"))\n",
    "\n",
    "        # Display normalized data\n",
    "        display(HTML(\"<h3>Normalized Data</h3>\"))\n",
    "        display(normalized_data.head().style.set_table_attributes('class=\"table table-striped\"').set_caption(\"Normalized Data\"))\n",
    "\n",
    "        # Display standardized data\n",
    "        display(HTML(\"<h3>Standardized Data</h3>\"))\n",
    "        display(standardized_data.head().style.set_table_attributes('class=\"table table-striped\"').set_caption(\"Standardized Data\"))\n",
    "        \n",
    "        # Display future predictions\n",
    "        display(HTML(\"<h3>Future Predictions</h3>\"))\n",
    "        display(future_df.style.set_table_attributes('class=\"table table-striped\"').set_caption(\"Future Predictions\"))\n",
    "\n",
    "        # Plot visualizations\n",
    "        plot_stock_prices(cleaned_data)\n",
    "        plot_future_predictions(future_df)\n",
    "        \n",
    "        # Provide download links\n",
    "        display(HTML('<h3>Download Links</h3>'))\n",
    "        display(HTML('<a href=\"cleaned_data.csv\" download>Download Cleaned Data CSV</a>'))\n",
    "        display(HTML('<a href=\"normalized_data.csv\" download>Download Normalized Data CSV</a>'))\n",
    "        display(HTML('<a href=\"standardized_data.csv\" download>Download Standardized Data CSV</a>'))\n",
    "        display(HTML('<a href=\"future_predictions.csv\" download>Download Future Predictions CSV</a>'))\n",
    "    \n",
    "    submit_button.on_click(on_button_click)\n",
    "    \n",
    "    display(ticker_input, start_date_input, end_date_input, submit_button)\n",
    "\n",
    "create_user_interface_with_downloads()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "205dd4eb-8312-42a0-8470-75bfc8dd2c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Return: 0.0009966930451517286\n",
      "Volatility: 0.023268382096358276\n"
     ]
    }
   ],
   "source": [
    "# Function to analyze historical performance\n",
    "def analyze_historical_performance(data):\n",
    "    mean_return = data['Close'].pct_change().mean()\n",
    "    volatility = data['Close'].pct_change().std()\n",
    "    return mean_return, volatility\n",
    "\n",
    "# Example usage\n",
    "mean_return, volatility = analyze_historical_performance(cleaned_yahoo_data)\n",
    "print(f\"Mean Return: {mean_return}\")\n",
    "print(f\"Volatility: {volatility}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b52e6568-a1dc-49a5-a4ef-2ea74d929499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Expected Return: 1.6617898249176748, Recommendation: Buy\n",
      "Gradient Boosting Expected Return: 1.6890635319662575, Recommendation: Buy\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate forecasted prices\n",
    "def evaluate_forecasted_prices(predictions, threshold=0.05):\n",
    "    expected_return = np.mean(predictions)\n",
    "    if expected_return > threshold:\n",
    "        recommendation = \"Buy\"\n",
    "    else:\n",
    "        recommendation = \"Do not buy\"\n",
    "    return expected_return, recommendation\n",
    "\n",
    "# Example usage\n",
    "expected_return_rf, recommendation_rf = evaluate_forecasted_prices(rf_future_predictions)\n",
    "expected_return_gb, recommendation_gb = evaluate_forecasted_prices(gb_future_predictions)\n",
    "print(f\"Random Forest Expected Return: {expected_return_rf}, Recommendation: {recommendation_rf}\")\n",
    "print(f\"Gradient Boosting Expected Return: {expected_return_gb}, Recommendation: {recommendation_gb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "578d944b-def5-407f-97d1-f2fefee0ed71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Sharpe Ratio: 3719500019996808.5\n",
      "Gradient Boosting Sharpe Ratio: 3780914948447313.0\n",
      "Random Forest Investment Recommendation: High potential for profit\n",
      "Gradient Boosting Investment Recommendation: High potential for profit\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate Sharpe ratio\n",
    "def calculate_sharpe_ratio(returns, risk_free_rate=0.01):\n",
    "    mean_return = np.mean(returns)\n",
    "    volatility = np.std(returns)\n",
    "    sharpe_ratio = (mean_return - risk_free_rate) / volatility\n",
    "    return sharpe_ratio\n",
    "\n",
    "# Example usage\n",
    "sharpe_ratio_rf = calculate_sharpe_ratio(rf_future_predictions)\n",
    "sharpe_ratio_gb = calculate_sharpe_ratio(gb_future_predictions)\n",
    "print(f\"Random Forest Sharpe Ratio: {sharpe_ratio_rf}\")\n",
    "print(f\"Gradient Boosting Sharpe Ratio: {sharpe_ratio_gb}\")\n",
    "\n",
    "# Recommendation based on Sharpe Ratio\n",
    "def recommend_investment(sharpe_ratio, threshold=1.0):\n",
    "    if sharpe_ratio > threshold:\n",
    "        recommendation = \"High potential for profit\"\n",
    "    else:\n",
    "        recommendation = \"High risk of loss\"\n",
    "    return recommendation\n",
    "\n",
    "# Example usage\n",
    "recommendation_rf = recommend_investment(sharpe_ratio_rf)\n",
    "recommendation_gb = recommend_investment(sharpe_ratio_gb)\n",
    "print(f\"Random Forest Investment Recommendation: {recommendation_rf}\")\n",
    "print(f\"Gradient Boosting Investment Recommendation: {recommendation_gb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc2ef9e6-22a5-4a92-a5e6-5fd582bc0366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Investment Recommendations</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Historical Performance</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Mean Return: 0.0009966930451517286</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Volatility: 0.023268382096358276</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Forecasted Prices Analysis</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Random Forest Expected Return: 1.6617898249176748, Recommendation: High potential for profit</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Gradient Boosting Expected Return: 1.6890635319662575, Recommendation: High potential for profit</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Risk Assessment</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Random Forest Sharpe Ratio: 3719500019996808.5, Recommendation: High potential for profit</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Gradient Boosting Sharpe Ratio: 3780914948447313.0, Recommendation: High potential for profit</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to display investment recommendations\n",
    "def display_investment_recommendations():\n",
    "    display(HTML(\"<h2>Investment Recommendations</h2>\"))\n",
    "    \n",
    "    # Historical Performance\n",
    "    display(HTML(f\"<h3>Historical Performance</h3>\"))\n",
    "    display(HTML(f\"<p>Mean Return: {mean_return}</p>\"))\n",
    "    display(HTML(f\"<p>Volatility: {volatility}</p>\"))\n",
    "    \n",
    "    # Forecasted Prices Analysis\n",
    "    display(HTML(f\"<h3>Forecasted Prices Analysis</h3>\"))\n",
    "    display(HTML(f\"<p>Random Forest Expected Return: {expected_return_rf}, Recommendation: {recommendation_rf}</p>\"))\n",
    "    display(HTML(f\"<p>Gradient Boosting Expected Return: {expected_return_gb}, Recommendation: {recommendation_gb}</p>\"))\n",
    "    \n",
    "    # Risk Assessment\n",
    "    display(HTML(f\"<h3>Risk Assessment</h3>\"))\n",
    "    display(HTML(f\"<p>Random Forest Sharpe Ratio: {sharpe_ratio_rf}, Recommendation: {recommendation_rf}</p>\"))\n",
    "    display(HTML(f\"<p>Gradient Boosting Sharpe Ratio: {sharpe_ratio_gb}, Recommendation: {recommendation_gb}</p>\"))\n",
    "\n",
    "display_investment_recommendations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9db095-c54c-4540-8560-c36d1379ea93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d62034-4060-40c4-8e1c-e05c5f91329b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab8a0b1-bfb5-4c41-a836-a73d851b7204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401fe335-1cb2-4179-8875-dc2fbe6fd15b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870df2ce-42c2-49dc-b937-1bc0667eb94b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1620c13-f19f-4787-90f7-431cbbe32f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218a3f51-c27b-433b-a62d-762bb99be61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab68491-23d1-4434-855a-cd5f0bcf3285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c606e87f-f581-4f3b-950d-7a45469ce8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b383e2d6-7e92-43f5-b652-b93598ee69b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4db6a6-8b18-47cd-b812-136b92e51ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6923f1c-50ed-4267-b415-4f8c820c5cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577f906c-e879-4769-b20a-f4c42d5222d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22385eeb-9613-4afb-adea-238298b11d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f77ffd7-ea67-4b79-a070-466d0227f402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce507cb-22a6-4e39-a533-4a75e65c2271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae33b7-131e-4611-b5ea-ab82ad453498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd367d77-63d9-4693-919b-ff8d9e8a7fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10e8edb-6105-4984-9d39-e1a657bec3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742f251-f640-459f-8c47-561bf766fb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f99ef4a-7d33-45aa-94be-12507759cbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b6b0f0-e5f1-42bb-8f2b-775876d2e5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567f338e-c39a-46f4-8643-a91e6ad2c15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd40553-a262-4a5e-a5d3-f03f3e8d4f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7045ad5-0637-44f0-9bac-9cd3fb517f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1be845d-1ab0-4abd-8871-0015a501a3de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187357d-851a-4b94-b4d9-e8cd6c2c0802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39fea5b-0e94-46e8-b8a0-4e948f6a4218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc6228-b1d0-4e7f-b668-bba333674fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048451d1-d56d-48e1-ad0f-ad62f9325d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783ae8d2-fe75-432a-9048-742f7e18a702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff3cb2-6c98-46da-92eb-87541f706c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
